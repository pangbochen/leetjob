https://zhuanlan.zhihu.com/p/58160982

来自于知乎的推荐系统召回模型

# 全能的FM模型

在排序阶段使用FM模型，GBDT+LR模型、DNN模型

个性化推荐系统里，首先的环节一般是召回阶段，工业界的常规做法是

**多路召回**
- 多路中每一路召回蔡旭一个不同的策略
- 统一的模型------将多回路召回改造成单回路召回策略

**召回与排序**
- 将召回阶段和排序阶段统一起来
- 改造成单模型单环节的


## 工业推荐系统整体架构是怎样


- 在线部分一般流程
  - 召回    
    - 得到千以下的规模
  - 粗排序
    - 简单的排序模型进一步减少后续环节传递的物品
  - 精排序
    - 复杂的模型对少量物品精准排序
  - 业务策略
    - 去除已读，推荐多样化，加入业务策略
  - 展示、收集
- 离线行为收集
  - 常规模型
  - 离线训练模型
  - 用户行为log

![流程](/img/推荐.jpg)

![两个阶段](/img/两个阶段.jpg)


由于粗排是可选的，分为两个阶段就够了，召回阶段和排序阶段。

召回阶段的主要职责是：从千万量级的候选物品里，采取简单模型将推荐物品候选集合快速筛减到千级别甚至百级别，这样将候选集合数量降下来，之后在排序阶段就可以上一些复杂模型，细致地对候选集进行个性化排序。

两阶段的不同任务
- 召回只能上简单模型，使用少量特征，保证泛化能力，尽量让用户感兴趣的物品在这个阶段能够找回来；
- 而排序阶段核心目标是要精准，因为它处理的物品数据量小，所以可以采用尽可能多的特征，使用比较复杂的模型，一切以精准为目标。



## 召回阶段怎么做呢？

一支穿云箭，千军万马来相见
- 穿云箭：召回系统
- 千军万马：多种花式的召回策略

常见的多路召回策略
- 兴趣标签
- 兴趣topic
- 兴趣实体
- 协同过滤
- 热门
- 相同地域

具体的多路做法
- 每一路召回：会来回K条相关物料，K作为一个超参数
- 优化点：不同用户对每一路的内容的感兴趣程度是不一样的
- 

## FM模型

FM模型有一些年龄了，2010年有Rendle提出，最近几年在各大厂大规模ctr预估和推荐中使用。
- 特征组合    对于推荐排序十分重要
- FM体现出来的是二阶特征组合

## 推荐排序模型
实用化的DNN版本的CTR模型一般采用MLP结构
- CTR的DNN处于NN的原始阶段:
  - CNN的特性天性(平移不变性)本身并不太适合推荐这个场景

- RNN
  - 捕捉用户行为序列
  - 利用时间信息的辅助结构可还行
  - 不适合作为CTR预估的主模型

- Transformer
  - 看起来很有希望
  - self-attention应该能够很好捕捉特征组合的工具

- 剩下的就是MLP了
  - 需要打造适合自身特点的DNN排序模型


## 从LR到SVM再到FM模型
比较成功的套路: 线性模型+人工特征组合来引入非线性 的模式

LR的主要问题是人工特征工程,难点在将特征组合的能力体现在模型层面

线性模型的改进
- 加入特征组合:类似多项式核SVM
- 优势
  - 直接将两两组合特征引入模型
- 劣势
  - 组合特征泛化能力弱
    - 尤其在大规模稀疏特征存在的场景下

多路召回的LR模型

- 通过 embedding化表征来解决大规模稀疏的问题
  - FM中学习的是单个特征的embedding,并不依赖摸个特定的特征组合是否出现过
  - 只要
  - 核心的特点是切换  0/1二值硬核匹配为向量软匹配


## MF matrix factorization
矩阵分解，本身是  很经典的 协同过滤模型

通过两个低维小矩阵的乘积计算来模拟真实用户的点击或评分产生的大协同信息稀疏矩阵

是编码了用户和物品协同信息的降维模型。

本质上MF模型看作是FM模型的特例

也就是
- 除去User ID 、 Item ID外的很多其他可用特征
  - 协同数据实值其中的一种
- 引入更多特征明显对于更精准地进行个性化推荐是非常有帮助的。


## 简单谈谈算法的效率问题

一眼看来：FM是n平方的时间复杂度

FFM, 中小数据规模做排序还好，没有大问题，数据量大起来后，急剧提升

FM-》DeepFM
- DeepFm做不出效果，那就别试着使用更复杂的模型，多想想其他方式比较好

有些复杂些的模型，也许效果确实好一些，在个别大公司也许真做上线了，但是很可能效果好不是算法的功劳，是工程能力强等多个因素共同导致的，人家能做，你未必做的了。

LR—>FM-->DeepFM—>干点其他的

## 优化FM的计算效率

对于second-order部分的改写

FM如今被广泛采用并成功替代LR模型的一个关键所在是：它可以通过数学公式改写，把表面貌似是 O(k*n^2 ) 的复杂度降低到 O(k*n) ，其中n是特征数量，k是特征的embedding size，


## 使用FM模型做统一的召回模型

丰富的多路召回逻辑
- 基于用户兴趣标签的召回
- 基于协同过滤的召回
- 基于命名体识别的召回
- 基于热点
- 基于地域
- 基于topic的召回

统一召回与多路召回
- 多路中各个模型得分不可比较，所以二阶段的ranking来统一分数
- 召回+ranking中
  - 每一路召回，需要确定返回多少个item才合适呢？多路下来超参数空间巨大
  - 统一的FM来做召回，做到更好的个性化，各路的超参数完全按照FM模型进行调整
- 客观的现实问题：召回和rank的人员是两拨人
  - 对于一个新路召回，ranking阶段没有把体现新增召回路特性的特征加入到ranking的阶段
    - 排序阶段以特征为表达方式
    - 召回以  路、策略、具体模型 的表达方式
  - 但同时，多路下新增一种召回方式会比较方便新加一路，具体表现为新增一种或者几种特征

### 开始来处理FM模型
首先都有两种阶段
- 离线阶段：通过，每个特征和这个特征对应的训练好的embedding向量，可以存好待用
- 将推荐系统记性抽象，能够得到相关的映射函数：F（user，item，context）
  - 得到用户是否对当前的这个物品感兴趣
  - 三种类型的特征构建
    - 用户相关特征集合
    - 物品相关特征集合
    - 上下文相关的特征集合


极简版的FM召回模型
- 首先不考虑上下文特征
- 第一步，对于某个用户，我们可以把属于这个用户子集合的特征，查询离线训练好的FM模型对应的特征embedding向量，然后将n个用户子集合的特征embedding向量累加，形成用户兴趣向量U，这个向量维度和每个特征的维度是相同的。
- 第二步，对于每个用户以及每个物品，我们可以利用步骤一中的方法，将每个用户的兴趣向量离线算好，存入在线数据库中比如Redis（用户ID及其对应的embedding），把物品的向量逐一离线算好，存入Faiss(Facebook开源的embedding高效匹配库)数据库中。

这样就完成了一个极简版的FM召回模型
- 将原来的O(n)级别的运算规模缩减到O(1)的级别
- 只考虑两个大组之间的交叉

一个直接的问题：
- 问题一：首先我们需要问自己，这种累加用户embedding特征向量以及累加物品embedding特征向量，之后做向量内积。这种算法符合FM模型的原则吗？和常规的FM模型是否等价？

相当于简化版本的FM只考虑用户特征集合U和物品特征集合I之间的两两特征组合

两个公式的直接对比
$$
<\sum_{i}U_{i}, \sum_{j}I_{j}>
$$
$$
<\sum_{i}\sum_{j}<U_{i}, U_{j}>>
$$



构造了一个完整的FM召回模型，通过构建user_embedding, context_embedding, item_embedding并且充分利用Faiss的高效embedding计算框架，构造高效执行的和FM计算等价的召回系统。

将多路召回融合到FM召回模型之中


将多路召回融入到FM的召回模型之中
- 本质上将一路召回转化为新加特征的模式
- 但是还是能够完成具体的转化

本身MF可以作为FM模型的一种特例来看待



## FM模型能够将召回和排序阶段一体化
两个阶段各司其职
- 召回考虑到泛化性，将候选物品集合数量降下来
- 排序则是根据用户特征、物品特征、上下文特征进行精准排名

两种互相trade-off的指标：准确度与精确度

只要目前的多路召回都能通过转化为特征的方式加入FM召回模型，而且FM排序阶段采用的特征在FM召回模型都采用。那么两者推荐效果是类似的。这意味着，从理论上说，是可以把两阶段模型简化为一阶段模型的。

从物品embedding匹配的速度来看待FM模型

召回阶段FM模型对User embedding和item embedding的

## summary for this document
LR-->FM-->wide& deep/DeepFM这一套技术为主


## 来自评论区的有关观点
1.召回层的离线评估方法不知有没有什么可以分享的呢，比如新上一个队列，召回了许多新item，感觉只能通过ab test来进行试验评估
- 可以用recall@topk评估质量

2.关于user embedding和item embedding，一般是怎么生成的？
- 


3.张老师，请问通过Graph embedding或者其他各种embedding方法，然后进行向量化召回和rank是不是后续的主流？
- 我觉得embedding召回是个趋势

4.写的太好了，不过有个疑问，真实场景，FM相对于SVD，能提升多少ctr了，是需要一步直接夸到FM吗
- 公司里做排序很少用svd吧，常用的lr。fm dnn啥的
- 


# 沉重的FFM模型

算法模型的诞生本身不也是一样吗？一个算法在某年某月被某人发明出来

它们出生后，如果人们觉得它有用，那它就安心本分地做好自己的工作，好好地服务你我他，如果哪天冒出更活力四射青春逼人的新模型，你觉得它没什么大用了，不也弃之如敝履吗？

正所谓：

  模型皆有意思
  模型皆需侍奉

## 两个问题
- 是否我们能够使用一个统一的模型，将多路召回改造成单模型单路召回策略？
- 是否存在一个模型，这个模型可以将召回阶段和排序阶段统一起来，就是把两阶段推荐环节改成单模型单环节推荐流程？

工业级推荐系统的整体架构
- 近线部分来说，主要目的是实时收集用户行为反馈，并选择训练实例，实时抽取拼接特征，并近乎实时地更新在线推荐模型。这样做的好处是用户的最新兴趣能够近乎实时地体现到推荐结果里。
- 离线部分而言，通过对线上用户点击日志的存储和清理，整理离线训练数据，并周期性地更新推荐模型。对于超大规模数据和机器学习模型来说，往往需要高效地分布式机器学习平台来对离线训练进行支持。

一般粗排是可选的，变为简单直接的召回和排序两个阶段。

召回阶段需要计算的候选集太大，速度快只能使用简单模型。


## FM模型来做召回意味什么？

FM/FFM模型一般作为典型的ranking阶段的模型

使用FM，FFM来做召回模型
- 温柔的做法：
  - 使用模型作为一路新的召回策略，
  - 使用模型召回代替原先多路召回的一路或者记录
- 激进的做法
  - FM/FFM 统一召回+ranking 的单阶段策略
  - 直接代替原先的多路召回策略
  - 用一个模型把召回和排序两阶段的事情全部做掉

embedding